{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW7-Part1_Myunghee_ID_2446752777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generative Models for Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) LSTM: Train an LSTM to mimic Russell’s style and thoughts:\n",
    "\n",
    "i. Concatenate your text ﬁles to create a corpus of Russell’s writings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1=\"./books/TPP.txt\"  # The Problems of Philosophy\n",
    "file2=\"./books/TAM.txt\"  # The Analysis of Mind\n",
    "file3=\"./books/MLOE.txt\" # Mysticism and Logic and Other Essays\n",
    "file4=\"./books/OKEWFSMP.txt\"\n",
    "# Our Knowledge of the External World as a Field for Scientiﬁc Method in Philosophy\n",
    "\n",
    "book1 = open(file1, encoding='UTF-8').read()\n",
    "book2 = open(file2, encoding='UTF-8').read()\n",
    "book3 = open(file3, encoding='UTF-8').read()\n",
    "book4 = open(file4, encoding='UTF-8').read()\n",
    "\n",
    "# lowercase\n",
    "book1 = book1.lower() \n",
    "book2 = book2.lower()\n",
    "book3 = book3.lower()\n",
    "book4 = book4.lower()\n",
    "\n",
    "# making a corpus of 5 books\n",
    "corpus = book1 + book2 + book3 + book4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Use a character-level representation for this model by using extended ASCII that has N = 256 characters. Each character will be encoded into a an integer using its ASCII code. Rescale the integers to the range [0,1], because LSTM uses a sigmoid activation function. LSTM will receive the rescaled integers as its input.2 \n",
    "\n",
    "2A smarter way is to parse the whole corpus to ﬁgure out how many distinct characters you have in the corpus (the number may be less than 256, e.g., 53). One can also disregard lowercase and uppercase letters or even remove punctuation characters such as !. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '\\n'), (1, ' '), (2, '!'), (3, '\"'), (4, '&'), (5, \"'\"), (6, '('), (7, ')'), (8, '*'), (9, '+'), (10, ','), (11, '-'), (12, '.'), (13, '/'), (14, '0'), (15, '1'), (16, '2'), (17, '3'), (18, '4'), (19, '5'), (20, '6'), (21, '7'), (22, '8'), (23, '9'), (24, ':'), (25, ';'), (26, '='), (27, '>'), (28, '?'), (29, '['), (30, ']'), (31, '_'), (32, 'a'), (33, 'b'), (34, 'c'), (35, 'd'), (36, 'e'), (37, 'f'), (38, 'g'), (39, 'h'), (40, 'i'), (41, 'j'), (42, 'k'), (43, 'l'), (44, 'm'), (45, 'n'), (46, 'o'), (47, 'p'), (48, 'q'), (49, 'r'), (50, 's'), (51, 't'), (52, 'u'), (53, 'v'), (54, 'w'), (55, 'x'), (56, 'y'), (57, 'z'), (58, '{'), (59, '|'), (60, '}'), (61, '\\xa0'), (62, '§'), (63, '·'), (64, 'â'), (65, 'æ'), (66, 'è'), (67, 'é'), (68, 'ë'), (69, 'î'), (70, 'ï'), (71, 'ô'), (72, 'ö'), (73, 'ü'), (74, 'œ'), (75, 'ŭ'), (76, 'α'), (77, 'β'), (78, 'γ'), (79, 'η'), (80, 'θ'), (81, 'ι'), (82, 'κ'), (83, 'λ'), (84, 'ν'), (85, 'ο'), (86, 'π'), (87, 'ρ'), (88, 'σ'), (89, 'τ'), (90, 'φ'), (91, 'ὴ'), (92, 'ή'), (93, 'ί'), (94, 'ὸ'), (95, 'ό'), (96, '′'), (97, '″'), (98, '\\ufeff')]\n"
     ]
    }
   ],
   "source": [
    "# figuring out distinct characters\n",
    "chc = sorted(list(set(corpus)))\n",
    "ch_lst = enumerate(chc)\n",
    "\n",
    "print(list(ch_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing irrelevant charaters\n",
    "\n",
    "for i in range(len(chc)):\n",
    "    if i == 1 or i==10 or i==12 or (31<i<58): # space, ',', '.', alphabet \n",
    "        continue\n",
    "    else:\n",
    "        corpus = corpus.replace(chc[i],\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, ',': 1, '.': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n"
     ]
    }
   ],
   "source": [
    "chc = sorted(list(set(corpus)))\n",
    "\n",
    "lu_lst =list(enumerate(chc))\n",
    "lu_dic = dict()  \n",
    "\n",
    "# making lookup table\n",
    "for i in range(len(lu_lst)):\n",
    "    lu_dic[lu_lst[i][1]]=lu_lst[i][0]\n",
    "print(lu_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Choose a window size, e.g., W = 100. \n",
    "\n",
    "iv. Inputs to the network will be the ﬁrst W−1 = 99 characters of each sequence, and the output of the network will be the Wth character of the sequence. Basically, we are training the network to predict each character using the 99 characters that precede it. Slide the window in strides of S = 1 on the text. For example, if W = 5 and S = 1 and we want to train the network with the sequence ABRACADABRA, The ﬁrst input to the network will be ABRA and the corresponding output will be C. The second input will be BRAC and the second output will be A, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 100  # window\n",
    "N = len(corpus)  # the number of charaters\n",
    "X = []\n",
    "y = []\n",
    "for i in range(N-(W-1)):\n",
    "    seq_X = corpus[i:i + W-1] # 99 characters of each seq.\n",
    "    seq_y = corpus[i + W -1] # 100th character\n",
    "    # encoding each character into an integer by lu_table\n",
    "    X.append([lu_dic[char] for char in seq_X])\n",
    "    y.append(lu_dic[seq_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.reshape(X, (len(X), 99, 1))\n",
    "# rescaling: dividing by max value, 28\n",
    "X_train = X_train /28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v. Note that the output has to be encoded using a one-hot encoding scheme with N = 256 (or less) elements. This means that the network reads integers, but outputs a vector of N = 256 (or less) elements.\n",
    "\n",
    "N=29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "# one hot encode the output variable\n",
    "y_train = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1534336, 99, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1534336, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vi. Use a single hidden layer for the LSTM with N = 256 (or less) memory units. (N=29)\n",
    "\n",
    "vii. Use a Softmax output layer to yield a probability prediction for each of the characters between 0 and 1. This is actually a character classiﬁcation problem with N classes. Choose log loss (cross entropy) as the objective function for the network (research what it means).3 \n",
    "\n",
    "3In Keras, you can use the ADAM optimization algorithm for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Myunghee\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "# LSTM model\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(29, input_shape=(99, 1)))\n",
    "lstm.add(Dense(29, activation='softmax'))\n",
    "lstm.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x. Use model checkpointing to keep the network weights to determine each time an improvement in loss is observed at the end of the epoch. Find the best set of weights in terms of loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "# checkpointing\n",
    "file=\"improved_weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "ch_pt=ModelCheckpoint(file, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks=[ch_pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "viii. We do not use a test dataset. We are using the whole training dataset to learn the probability of each character in a sequence. We are not seeking for a very accurate model. Instead we are interested in a generalization of the dataset that can mimic the gist of the text. \n",
    "\n",
    "ix. Choose a reasonable number of epochs4 for training, considering your computational power (e.g., 30, although the network will need more epochs to yield a better model).\n",
    "\n",
    "4one epoch = one forward pass and one backward pass of all the training examples. \n",
    "\n",
    "batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you’ll need. \n",
    "\n",
    "number of iterations = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two diﬀerent passes). See https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Myunghee\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1534336/1534336 [==============================] - 609s 397us/step - loss: 2.7296\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.72961, saving model to improved_weights-01-2.7296.hdf5\n",
      "Epoch 2/10\n",
      "1534336/1534336 [==============================] - 601s 392us/step - loss: 2.6030\n",
      "\n",
      "Epoch 00002: loss improved from 2.72961 to 2.60301, saving model to improved_weights-02-2.6030.hdf5\n",
      "Epoch 3/10\n",
      "1534336/1534336 [==============================] - 650s 424us/step - loss: 2.5425\n",
      "\n",
      "Epoch 00003: loss improved from 2.60301 to 2.54249, saving model to improved_weights-03-2.5425.hdf5\n",
      "Epoch 4/10\n",
      "1534336/1534336 [==============================] - 851s 555us/step - loss: 2.4945s - ETA\n",
      "\n",
      "Epoch 00004: loss improved from 2.54249 to 2.49454, saving model to improved_weights-04-2.4945.hdf5\n",
      "Epoch 5/10\n",
      "1534336/1534336 [==============================] - 1060s 691us/step - loss: 2.4554\n",
      "\n",
      "Epoch 00005: loss improved from 2.49454 to 2.45537, saving model to improved_weights-05-2.4554.hdf5\n",
      "Epoch 6/10\n",
      "1534336/1534336 [==============================] - 914s 596us/step - loss: 2.4273\n",
      "\n",
      "Epoch 00006: loss improved from 2.45537 to 2.42726, saving model to improved_weights-06-2.4273.hdf5\n",
      "Epoch 7/10\n",
      "1534336/1534336 [==============================] - 779s 508us/step - loss: 2.4054\n",
      "\n",
      "Epoch 00007: loss improved from 2.42726 to 2.40543, saving model to improved_weights-07-2.4054.hdf5\n",
      "Epoch 8/10\n",
      "1534336/1534336 [==============================] - 685s 447us/step - loss: 2.3861\n",
      "\n",
      "Epoch 00008: loss improved from 2.40543 to 2.38612, saving model to improved_weights-08-2.3861.hdf5\n",
      "Epoch 9/10\n",
      "1534336/1534336 [==============================] - 672s 438us/step - loss: 2.3675\n",
      "\n",
      "Epoch 00009: loss improved from 2.38612 to 2.36753, saving model to improved_weights-09-2.3675.hdf5\n",
      "Epoch 10/10\n",
      "1534336/1534336 [==============================] - 586s 382us/step - loss: 2.3494\n",
      "\n",
      "Epoch 00010: loss improved from 2.36753 to 2.34942, saving model to improved_weights-10-2.3494.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222ca9837b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(X_train, y_train, epochs=10, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xi. Use the network with the best weights to generate 1000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file with the smallest loss value\n",
    "file = \"improved_weights-10-2.3494.hdf5\"\n",
    "lstm.load_weights(file)\n",
    "lstm.compile(loss='categorical_crossentropy', optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are those who take mental phenomena naively, just as they would physical phenomena. this school of psychologists tends not to emphasize the object.\n"
     ]
    }
   ],
   "source": [
    "seed = 'There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.'\n",
    "seed=seed.lower()\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 0, 3, 21, 0, 22, 10, 7, 27, 0, 25, 17, 23, 14, 6, 0, 18, 10, 27, 21, 11, 5, 3, 14, 0, 18, 10, 7, 16, 17, 15, 7, 16, 3, 2, 0, 22, 10, 11, 21, 0, 21, 5, 10, 17, 17, 14, 0, 17, 8, 0, 18, 21, 27, 5, 10, 17, 14, 17, 9, 11, 21, 22, 21, 0, 22, 7, 16, 6, 21, 0, 16, 17, 22, 0, 22, 17, 0, 7, 15, 18, 10, 3, 21, 11, 28, 7, 0, 22, 10, 7, 0, 17, 4, 12, 7, 5, 22, 2]\n"
     ]
    }
   ],
   "source": [
    "# input sequence (99 characters) from the seed\n",
    "seq = []\n",
    "for char in seed:\n",
    "    seq.append(lu_dic[char])\n",
    "in_seq = seq[-99:]  # 99 characters\n",
    "print(in_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: ',', 2: '.', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# making reverse lookup table\n",
    "re_dic = dict()\n",
    "for i in range(len(lu_lst)):\n",
    "    re_dic[lu_lst[i][0]]=lu_lst[i][1]\n",
    "print(re_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are those who take mental phenomena naively, just as they would physical phenomena. this school of psychologists tends not to emphasize the object.\n",
      " the seale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale the teale"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(seed)\n",
    "# generating 1000 characters\n",
    "for i in range(1000):\n",
    "    X_test = np.reshape(in_seq, (1, 99, 1))\n",
    "    X_test = X_test / 28\n",
    "    pred = lstm.predict(X_test, verbose=0)\n",
    "    out = np.argmax(pred) # output\n",
    "    ch = re_dic[out]  # converting output to character\n",
    "    \n",
    "    sys.stdout.write(ch)\n",
    "    in_seq.append(out) # adding output to input sequence\n",
    "    in_seq = in_seq[-99:] # selecting 99 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
